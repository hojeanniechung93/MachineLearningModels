{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CAPSTONE PROJECT: DECISION TREES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question: Based on the data, can we predict what category of apps will be used?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the data, we are going to predict the category of application the device will use in the future. The assumption is that if a device uses a certain type of application in the past, the user of the device will be more inclined to use an application of the same type in the future. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data was pulled in from 5 files: ApiCalls, ApiNames, AppInteractivity, DeviceCensus, and StoreSearch. The tables were concatenated and merged into a FinalData DataFrame that I wanted to use which included Categories: DateId, nDeviceId, appSessionGuid, AppName, InFocusDurationMS, EngagementDurationMS, appName an Category. In order to run the dataframe through the DecisionTreeClassfier, a new class MultiLabelEncoder was created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hochung\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2785: DtypeWarning: Columns (101,122,123) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Category      DateId  nDeviceId\n",
      "0         0  20180420.0       79.0\n",
      "1         0  20180420.0       79.0\n",
      "2         0  20180420.0       79.0\n",
      "3         0  20180420.0       79.0\n",
      "4         0  20180420.0       79.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hochung\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.51      0.42      0.46      6007\n",
      "          1       0.65      0.56      0.60      8505\n",
      "          2       0.76      0.14      0.24       175\n",
      "          3       0.45      0.45      0.45      4932\n",
      "          4       0.56      0.39      0.46    112919\n",
      "          5       0.64      0.71      0.67    398394\n",
      "          6       0.61      0.61      0.61    112972\n",
      "          7       0.00      0.00      0.00       193\n",
      "          8       0.00      0.00      0.00       106\n",
      "          9       0.66      0.35      0.46       359\n",
      "         10       0.43      0.05      0.09       190\n",
      "         11       0.61      0.61      0.61    196603\n",
      "         12       0.54      0.60      0.57      5889\n",
      "         13       0.55      0.51      0.53     80923\n",
      "         14       0.48      0.47      0.48      7507\n",
      "         15       0.64      0.52      0.57       956\n",
      "         16       0.72      0.82      0.77   2161095\n",
      "         17       0.58      0.54      0.56    526928\n",
      "         18       0.51      0.53      0.52       921\n",
      "         19       0.57      0.45      0.50    512406\n",
      "         20       0.57      0.44      0.50    590842\n",
      "         21       0.51      0.54      0.52      4331\n",
      "         22       0.81      0.77      0.79       985\n",
      "         23       0.58      0.52      0.55    305330\n",
      "\n",
      "avg / total       0.64      0.65      0.64   5039468\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Spyder Editor\n",
    "\n",
    "This is a temporary script file.\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "ApiCalls = pd.read_table(\"../../Desktop/Data/ApiCalls.tsv\")\n",
    "ApiNames=pd.read_table(\"../../Desktop/Data/ApiNames.tsv\")\n",
    "AppInteractivity = pd.read_table(\"../../Desktop/Data/AppInteractivity.tsv\")\n",
    "DeviceCensus = pd.read_table(\"../../Desktop/Data/DeviceCensus.tsv\")\n",
    "StoreSearch=pd.read_table(\"../../Desktop/Data/StoreSearch.tsv\")\n",
    "\n",
    "#whittle the dataframes for concatnation\n",
    "AppInter_adj = pd.DataFrame(AppInteractivity[[\"DateId\",\"nDeviceId\",\"appSessionGuid\",\"AppName\",\"InFocusDurationMS\",\"EngagementDurationMS\"]])\n",
    "SS_adj = pd.DataFrame(StoreSearch[[\"Category\",\"appName\"]])\n",
    "SS_adj.columns=[\"Category\",\"AppName\"]\n",
    "\n",
    "#Concat\n",
    "SourceData = pd.concat([ApiCalls,AppInter_adj,ApiNames],axis=0,ignore_index = True, sort=False)\n",
    "\n",
    "#Merge\n",
    "FinalData = pd.merge(SS_adj,SourceData, on=[\"AppName\"])\n",
    "\n",
    "\n",
    "#Based on previous data, the device will use an x type application tomorrow\n",
    "#Using Decision Trees\n",
    "import sklearn.datasets as datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "\n",
    "#Create a MultiColumLabelEncoder\n",
    "class MultiColumnLabelEncoder(preprocessing.LabelEncoder):\n",
    "    \"\"\"\n",
    "    Wraps sklearn LabelEncoder functionality for use on multiple columns of a\n",
    "    pandas dataframe.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, columns=None):\n",
    "        self.columns = columns\n",
    "\n",
    "    def fit(self, dframe):\n",
    "        # if columns are provided, iterate through and get `classes_`\n",
    "        if self.columns is not None:\n",
    "            # ndarray to hold LabelEncoder().classes_ for each\n",
    "            # column; should match the shape of specified `columns`\n",
    "            self.all_classes_ = np.ndarray(shape=self.columns.shape,\n",
    "                                           dtype=object)\n",
    "            self.all_encoders_ = np.ndarray(shape=self.columns.shape,\n",
    "                                            dtype=object)\n",
    "            for idx, column in enumerate(self.columns):\n",
    "                # fit LabelEncoder to get `classes_` for the column\n",
    "                le = preprocessing.LabelEncoder()\n",
    "                le.fit(dframe.loc[:, column].values)\n",
    "                # append the `classes_` to our ndarray container\n",
    "                self.all_classes_[idx] = (column,\n",
    "                                          np.array(le.classes_.tolist(),\n",
    "                                                  dtype=object))\n",
    "                # append this column's encoder\n",
    "                self.all_encoders_[idx] = le\n",
    "        else:\n",
    "            # no columns specified; assume all are to be encoded\n",
    "            self.columns = dframe.iloc[:, :].columns\n",
    "            self.all_classes_ = np.ndarray(shape=self.columns.shape,\n",
    "                                           dtype=object)\n",
    "            for idx, column in enumerate(self.columns):\n",
    "                le = preprocessing.LabelEncoder()\n",
    "                le.fit(dframe.loc[:, column].values)\n",
    "                self.all_classes_[idx] = (column,\n",
    "                                          np.array(le.classes_.tolist(),\n",
    "                                                  dtype=object))\n",
    "                self.all_encoders_[idx] = le\n",
    "        return self\n",
    "\n",
    "    def fit_transform(self, dframe):\n",
    "        # if columns are provided, iterate through and get `classes_`\n",
    "        if self.columns is not None:\n",
    "            # ndarray to hold LabelEncoder().classes_ for each\n",
    "            # column; should match the shape of specified `columns`\n",
    "            self.all_classes_ = np.ndarray(shape=self.columns.shape,\n",
    "                                           dtype=object)\n",
    "            self.all_encoders_ = np.ndarray(shape=self.columns.shape,\n",
    "                                            dtype=object)\n",
    "            self.all_labels_ = np.ndarray(shape=self.columns.shape,\n",
    "                                          dtype=object)\n",
    "            for idx, column in enumerate(self.columns):\n",
    "                # instantiate LabelEncoder\n",
    "                le = preprocessing.LabelEncoder()\n",
    "                # fit and transform labels in the column\n",
    "                dframe.loc[:, column] =\\\n",
    "                    le.fit_transform(dframe.loc[:, column].values)\n",
    "                # append the `classes_` to our ndarray container\n",
    "                self.all_classes_[idx] = (column,\n",
    "                                          np.array(le.classes_.tolist(),\n",
    "                                                  dtype=object))\n",
    "                self.all_encoders_[idx] = le\n",
    "                self.all_labels_[idx] = le\n",
    "        else:\n",
    "            # no columns specified; assume all are to be encoded\n",
    "            self.columns = dframe.iloc[:, :].columns\n",
    "            self.all_classes_ = np.ndarray(shape=self.columns.shape,\n",
    "                                           dtype=object)\n",
    "            for idx, column in enumerate(self.columns):\n",
    "                le = preprocessing.LabelEncoder()\n",
    "                dframe.loc[:, column] = le.fit_transform(\n",
    "                        dframe.loc[:, column].values)\n",
    "                self.all_classes_[idx] = (column,\n",
    "                                          np.array(le.classes_.tolist(),\n",
    "                                                  dtype=object))\n",
    "                self.all_encoders_[idx] = le\n",
    "        return dframe\n",
    "\n",
    "    def transform(self, dframe):\n",
    "        ##Transform labels to normalized encoding.\n",
    "        if self.columns is not None:\n",
    "            for idx, column in enumerate(self.columns):\n",
    "                dframe.loc[:, column] = self.all_encoders_[\n",
    "                    idx].transform(dframe.loc[:, column].values)\n",
    "        else:\n",
    "            self.columns = dframe.iloc[:, :].columns\n",
    "            for idx, column in enumerate(self.columns):\n",
    "                dframe.loc[:, column] = self.all_encoders_[idx]\\\n",
    "                    .transform(dframe.loc[:, column].values)\n",
    "        return dframe.loc[:, self.columns].values\n",
    "\n",
    "    def inverse_transform(self, dframe):\n",
    "        ###Transform labels back to original encoding.\n",
    "        if self.columns is not None:\n",
    "            for idx, column in enumerate(self.columns):\n",
    "                dframe.loc[:, column] = self.all_encoders_[idx]\\\n",
    "                    .inverse_transform(dframe.loc[:, column].values)\n",
    "        else:\n",
    "            self.columns = dframe.iloc[:, :].columns\n",
    "            for idx, column in enumerate(self.columns):\n",
    "                dframe.loc[:, column] = self.all_encoders_[idx]\\\n",
    "                    .inverse_transform(dframe.loc[:, column].values)\n",
    "        return dframe\n",
    "    \n",
    "#Pick out Mixed type data frames\n",
    "FeaturePicker = pd.DataFrame(FinalData[[\"Category\",\"DateId\",\"nDeviceId\"]])        \n",
    "# get `object` columns\n",
    "df_object_columns = FeaturePicker.iloc[:, :].select_dtypes(include=['object']).columns\n",
    "\n",
    "#instantiate MultiColumnLabelEncoder\n",
    "mcle = MultiColumnLabelEncoder(columns=df_object_columns)\n",
    "\n",
    "#fit to FeaturePicker\n",
    "mcle.fit(FeaturePicker)\n",
    "\n",
    "#transform the FeaturePicker\n",
    "mcle.transform(FeaturePicker)\n",
    "print(FeaturePicker.head())\n",
    "\n",
    "#inverse data\n",
    "#mcle.inverse_transform(FinalData)\n",
    "#X=Feature\n",
    "#Y=Label\n",
    "\n",
    "y=FeaturePicker.Category.to_frame()\n",
    "X_train, X_test, y_train, y_test=train_test_split(FeaturePicker.iloc[:,1:],y,test_size=0.33,random_state=42)\n",
    "\n",
    "\n",
    "#Sklearn will generate a decision tree for your dataset using an optimized version of the CART algorithm when you run the following code\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtree = DecisionTreeClassifier()\n",
    "dtree.fit(X_train,y_train)\n",
    "\n",
    "#metrics\n",
    "import sklearn.metrics as met\n",
    "y_pred = dtree.predict(X_test)\n",
    "print(met.classification_report(y_test,y_pred))\n",
    "#Decode the arrays back into string\n",
    "\n",
    "#Graph the Tree\n",
    "from sklearn.externals.six import StringIO  \n",
    "from IPython.display import Image  \n",
    "from sklearn.tree import export_graphviz\n",
    "import pydotplus\n",
    "dot_data = StringIO()\n",
    "export_graphviz(dtree, out_file=dot_data,  \n",
    "                filled=True, rounded=True,\n",
    "                special_characters=True)\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "Image(graph.create_png())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "PATH = \"C:\\Users\\hochung\\Documents\\Python Notebooks\"\n",
    "Image(filename = PATH + \"Results_For_Capstone.png\", width=100, height=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
